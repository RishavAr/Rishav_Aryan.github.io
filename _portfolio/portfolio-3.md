---
title: "LLM-Powered Cybersecurity Evaluator"
collection: portfolio
date: 2025-08-10
share: false
excerpt: "Adversarial benchmarking framework for evaluating LLM security robustness."
github: "https://github.com/RishavAr/AI_SECURITY_EVAL"
tech: "Hugging Face, Transformers, PyTorch"
---

### ğŸ” Overview
Built a large-scale adversarial evaluation framework to benchmark LLMs against malicious security payloads.

### ğŸ“¦ Dataset
- **31k+ samples** derived from PayloadsAllTheThings  
- 100+ vulnerability categories balanced with benign inputs  

### ğŸ“ˆ Performance
- Achieved **88% detection accuracy**
- Benchmarked GPT-3.5, GPT-4o, GPT-4o-mini

### ğŸ”— Links
- ğŸ’» **Code:** [GitHub Repository](https://github.com/RishavAr/AI_SECURITY_EVAL)

